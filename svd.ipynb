{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Intuition for LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "_=torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Rank-Deficient matrix W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.8501, -4.1679, -1.2931, -1.7376, -2.5698, -3.2220, -1.4271, -1.2982,\n",
      "          0.2702,  1.2163],\n",
      "        [ 3.2737, -4.7411, -1.4644, -1.9621, -2.9216, -3.6760, -1.6166, -1.4949,\n",
      "          0.2975,  1.3819],\n",
      "        [-0.0141, -3.3560, -1.5177, -2.4550, -2.1852, -1.7979, -1.6433,  0.2801,\n",
      "          0.9375,  1.1010],\n",
      "        [-0.8365,  0.4910,  0.0490, -0.0243,  0.2776,  0.5523,  0.0609,  0.4404,\n",
      "          0.1243, -0.1169],\n",
      "        [-3.9740, -0.6857, -1.1295, -2.3176, -0.6460,  1.0025, -1.1858,  2.3367,\n",
      "          1.4298,  0.4341],\n",
      "        [ 0.7376, -0.9989, -0.2987, -0.3915, -0.6132, -0.7910, -0.3304, -0.3424,\n",
      "          0.0478,  0.2886],\n",
      "        [-2.2472,  1.8582,  0.3750,  0.3281,  1.0966,  1.7733,  0.4272,  1.1393,\n",
      "          0.1840, -0.4908],\n",
      "        [ 0.7821, -0.5984, -0.1087, -0.0790, -0.3502, -0.5912, -0.1251, -0.4004,\n",
      "         -0.0775,  0.1550],\n",
      "        [-0.0482, -0.4016, -0.1912, -0.3150, -0.2638, -0.1991, -0.2066,  0.0602,\n",
      "          0.1267,  0.1342],\n",
      "        [ 0.6151, -0.9209, -0.2887, -0.3906, -0.5685, -0.7068, -0.3184, -0.2785,\n",
      "          0.0642,  0.2695]])\n"
     ]
    }
   ],
   "source": [
    "## rank deficient means basically,the number of independent vectors/columns are lesser than the dimension of the matrix\n",
    "d,k=10,10\n",
    "\n",
    "w_rank=2\n",
    "W=torch.randn(d,w_rank)@torch.randn(w_rank,d)\n",
    "print(W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the rank of the matrix using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank of W is:2\n"
     ]
    }
   ],
   "source": [
    "W_rank=np.linalg.matrix_rank(W)\n",
    "print(f\"rank of W is:{W_rank}\") ## these are the number of linearly independent columns/vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of B: torch.Size([10, 2])\n",
      "shape of A:torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "## SVD on W (W=U*S*V^T)\n",
    "U,S,V=torch.svd(W)\n",
    "\n",
    "## for rank-r factorization, we are keeping only first r singular values (and correspoding columns of U and V)\n",
    "U_r=U[:,:W_rank]\n",
    "S_r=torch.diag(S[:W_rank])\n",
    "V_r=V[:,:W_rank].transpose(-1,-2) # Transpose V_r to get the right dimensions\n",
    "\n",
    "## computing C=U_r * S_r and R=V_r\n",
    "B=U_r @ S_r\n",
    "A=V_r\n",
    "\n",
    "print(f\"shape of B: {B.shape}\")\n",
    "print(f\"shape of A:{A.shape}\")\n",
    "\n",
    "## These are the low rank representations of W (LORA)--> 10*2 and 2*10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original y using W:\n",
      " tensor([-0.0038,  2.8550,  2.2213,  0.3943,  2.1021,  2.0980, -1.8128,  0.1020,\n",
      "         1.4823,  1.6640])\n",
      "\n",
      "\n",
      "y computed using BA:\n",
      " tensor([-0.0038,  2.8550,  2.2213,  0.3943,  2.1021,  2.0980, -1.8128,  0.1020,\n",
      "         1.4823,  1.6640])\n"
     ]
    }
   ],
   "source": [
    "## now generating random bias and input\n",
    "bias =torch.randn(d)\n",
    "x=torch.randn(d)\n",
    "\n",
    "y=W@x+bias ## broadcasting will automatically take care of dimensions\n",
    "\n",
    "## computing y'=CRx+b\n",
    "y_prime=(B@A)@x+bias\n",
    "\n",
    "print(\"original y using W:\\n\",y)\n",
    "print(\"\\n\")\n",
    "print(\"y computed using BA:\\n\",y_prime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of elements of W: 100\n",
      "Total number of element of B and A 40\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of elements of W:\",W.nelement())\n",
    "print(\"Total number of element of B and A\",B.nelement()+A.nelement())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
